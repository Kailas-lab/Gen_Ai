{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select Translation Style:\n",
      "1. Casual (Native Speaker Style)\n",
      "2. Formal (Official Document)\n",
      "3. Poetic (Rhyming Translation)\n",
      "4. Bilingual (With English Reference)\n",
      "\n",
      "üîÑ Translated Text (tamil - Style 3):\n",
      "Several options, depending on the nuance you want to convey:\n",
      "\n",
      "**Option 1 (Simple and sweet):**\n",
      "\n",
      "‡Æ®‡ØÄ‡Æ∞‡Øç ‡Æ®‡Æø‡Æ≤‡Æµ‡ØÅ ‡Æ™‡Øã‡Æ≤ (Neer nilavu pola) - You are like the moon.  This is straightforward but retains a poetic feel due to the use of \"Neer\" (you, polite form).\n",
      "\n",
      "**Option 2 (Emphasizing beauty):**\n",
      "\n",
      "‡Æ®‡ØÄ‡Æ∞‡Øç ‡Æ®‡Æø‡Æ≤‡Æµ‡Øà‡Æ™‡Øç ‡Æ™‡Øã‡Æ≤‡Øç ‡ÆÖ‡Æ¥‡Æï‡ØÅ (Neer nilavai pol azhagu) - You are beautiful like the moon. This adds the word \"azhagu\" (beauty).\n",
      "\n",
      "**Option 3 (More metaphorical, emphasizing grace):**\n",
      "\n",
      "‡Æ®‡Æø‡Æ≤‡Æµ‡Æø‡Æ©‡Øç ‡ÆÆ‡ØÜ‡Æ©‡Øç‡ÆÆ‡Øà ‡Æ®‡ØÄ‡Æ∞‡Æø‡Æ≤‡Øç (Nilavin menmai neeril) - The moon's softness is in you. This is more metaphorical, highlighting a gentle quality.\n",
      "\n",
      "\n",
      "**Option 4 (A more elaborate rhyming couplet):**\n",
      "\n",
      "‡Æµ‡Ææ‡Æ©‡Æø‡Æ≤‡Øç ‡Æ®‡Æø‡Æ≤‡Ææ ‡Æí‡Æ≥‡Æø ‡Æµ‡ØÄ‡Æö‡ØÅ‡Æµ‡Æ§‡ØÅ ‡Æ™‡Øã‡Æ≤,\n",
      "‡Æâ‡Æ©‡Øç ‡ÆÖ‡Æ¥‡Æï‡ØÅ ‡Æï‡Æ£‡Øç‡Æï‡Æ≥‡Øà‡Æ§‡Øç ‡Æ§‡Øä‡Æü‡Øç‡Æü‡ØÅ‡Æö‡Øç ‡Æö‡ØÜ‡Æ≤‡Øç‡Æ≤‡ØÅ‡Æ§‡ØÅ. (Vaanil nilaa oli veesuvathu pola, Un azhagu kangalai thottu seluthu)\n",
      "\n",
      "Meaning: Like the moon sheds light in the sky,\n",
      "Your beauty touches and moves the eyes.\n",
      "\n",
      "\n",
      "The best option depends on the specific context and desired emotional effect.  Option 4 is the most poetic and rhyming, but the others are simpler and may be more suitable depending on the situation.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Set API Key (Ensure security in production)\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCupd3Dn6SV1lOm2IW6GK89kHmppz7H2LM\"\n",
    "\n",
    "# Initialize LLM (Google Gemini)\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.7)\n",
    "\n",
    "#  Define Translation Styles\n",
    "templates = {\n",
    "    \"1\": PromptTemplate(\n",
    "        input_variables=[\"text\", \"target_language\"],\n",
    "        template=\"Translate this into {target_language} but make it sound casual and fun, as if a native speaker is saying it:\\n\\n{text}\"\n",
    "    ),\n",
    "    \"2\": PromptTemplate(\n",
    "        input_variables=[\"text\", \"target_language\"],\n",
    "        template=\"You are a professional translator. Please translate the following document into {target_language} while maintaining proper grammar and formality:\\n\\n{text}\"\n",
    "    ),\n",
    "    \"3\": PromptTemplate(\n",
    "        input_variables=[\"text\", \"target_language\"],\n",
    "        template=\"Translate this into {target_language} with a poetic or rhyming touch:\\n\\n{text}\"\n",
    "    ),\n",
    "    \"4\": PromptTemplate(\n",
    "        input_variables=[\"text\", \"target_language\"],\n",
    "        template=\"Translate the given text to {target_language} and also provide the English meaning for reference:\\n\\n{text}\"\n",
    "    )\n",
    "}\n",
    "\n",
    "#  User Inputs\n",
    "text_to_translate = input(\"Enter the text you want to translate: \")\n",
    "target_language = input(\"Enter the target language (e.g., French, Spanish, Hindi): \")\n",
    "\n",
    "#  Choose Translation Style\n",
    "print(\"\\nSelect Translation Style:\")\n",
    "print(\"1. Casual (Native Speaker Style)\")\n",
    "print(\"2. Formal (Official Document)\")\n",
    "print(\"3. Poetic (Rhyming Translation)\")\n",
    "print(\"4. Bilingual (With English Reference)\")\n",
    "style_choice = input(\"Enter your choice (1-4): \")\n",
    "\n",
    "#  Validate Choice & Execute Only One\n",
    "if style_choice in templates:\n",
    "    chosen_template = templates[style_choice]  # Pick only the selected template\n",
    "    chain = LLMChain(llm=llm, prompt=chosen_template)  # Create chain only for the selected template\n",
    "\n",
    "    #  Run the chain and get the response\n",
    "    response = chain.run({\"text\": text_to_translate, \"target_language\": target_language})\n",
    "\n",
    "    #  Display Only the Selected Translation\n",
    "    print(f\"\\n Translated Text ({target_language} - Style {style_choice}):\")\n",
    "    print(response)\n",
    "else:\n",
    "    print(\"Invalid choice! Please select between 1-4.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**String Prompt Template**\n",
    "\n",
    "These prompt templates are used to format a single string, and generally are used for simpler inputs. \n",
    "\n",
    "The PromptTemplate only creates text prompts; it does not generate responses.\n",
    "You need to pass the formatted prompt to an LLM (like OpenAI GPT, Gemini, or Llama) to get a joke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Tell me a joke about cats')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "\n",
    "prompt_template.invoke({\"topic\": \"cats\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chat Prompt Template**\n",
    "\n",
    "These prompt templates are used to format a list of messages. These \"templates\" consist of a list of templates themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me a joke about cats', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define the chat prompt template correctly\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "   (\"system\", \"You are a helpful assistant\"),\n",
    "   (\"user\", \"Tell me a joke about {topic}\")\n",
    "])\n",
    "\n",
    "# Invoke the prompt with a topic\n",
    "formatted_prompt = prompt_template.invoke({\"topic\": \"cats\"})\n",
    "\n",
    "# Print the output\n",
    "print(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Messages PlaceHolder Template**\n",
    "\n",
    "This prompt template is responsible for adding a list of messages in a particular place. In the above ChatPromptTemplate, we saw how we could format two messages, each one a string. But what if we wanted the user to pass in a list of messages that we would slot into a particular spot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! How can I help you?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me a joke about cats.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Define the chat prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "   (\"system\", \"You are a helpful assistant\"),\n",
    "   MessagesPlaceholder(variable_name=\"msgs\")\n",
    "])\n",
    "\n",
    "# Provide multiple messages\n",
    "messages = [\n",
    "    HumanMessage(content=\"Hi!\"),\n",
    "    AIMessage(content=\"Hello! How can I help you?\"),\n",
    "    HumanMessage(content=\"Tell me a joke about cats.\"),\n",
    "]\n",
    "\n",
    "# Invoke the prompt with multiple messages\n",
    "formatted_prompt = prompt_template.invoke({\"msgs\": messages})\n",
    "\n",
    "# Print the formatted prompt\n",
    "print(formatted_prompt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
